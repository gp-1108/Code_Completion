from torch.utils.data import Dataset
import random

class CodeDataset(Dataset):
    def __init__(self, file_contents: list[str], tokenizer, num_samples: int = 50, 
                 min_lengths: tuple = (20, 10, 20), max_lengths: tuple = (200, 50, 200)):
        """
        Args:
            file_contents (list[str]): A list of strings, where each string is the content of a code file.
            tokenizer: Tokenizer object to tokenize the code content.
            num_samples (int): The number of code completion examples to generate.
            min_lengths (tuple): A tuple (x, y, z) where x is the min prefix token count, y is the min middle token count, and z is the min suffix token count.
            max_lengths (tuple): A tuple (x, y, z) where x is the max prefix token count, y is the max middle token count, and z is the max suffix token count.
        """
        self.tokenizer = tokenizer
        self.examples = []
        
        # Unpack the min and max lengths for prefix, middle, and suffix (in tokens)
        self.min_prefix_length, self.min_middle_length, self.min_suffix_length = min_lengths
        self.max_prefix_length, self.max_middle_length, self.max_suffix_length = max_lengths
        
        # Generate code completion examples based on tokenized data
        self._generate_examples(file_contents, num_samples)
    
    def _generate_examples(self, file_contents: list[str], num_samples: int):
        """
        Generates examples from the provided file contents using tokenized data.
        The examples are generated by randomly selecting a cursor position in the content
        and extracting prefix, middle, and suffix segments around the cursor.
        Args:
            file_contents (list[str]): A list of strings, each representing the content 
                                       from which examples will be generated.
            num_samples (int): The number of samples to generate.
        """
        for content in file_contents:
            tokens = self.tokenizer(content, return_tensors="pt")["input_ids"].squeeze(0).tolist()
            content_length = len(tokens)

            # Ensure the content is long enough to generate examples with min token counts
            if content_length < self.min_prefix_length + self.min_middle_length + self.min_suffix_length:
                continue
            
            for _ in range(num_samples):
                # Randomly select the middle length (in tokens)
                middle_length = random.randint(self.min_middle_length, self.max_middle_length)
                
                # Randomly select the cursor position ensuring space for middle and suffix (in tokens)
                max_cursor_position = content_length - middle_length - self.min_suffix_length
                if max_cursor_position <= self.min_prefix_length:
                    continue

                cursor_position = random.randint(self.min_prefix_length, max_cursor_position)
                
                # Randomly determine prefix and suffix lengths based on the cursor position and available space
                prefix_length = random.randint(self.min_prefix_length, min(cursor_position, self.max_prefix_length))
                suffix_length = random.randint(self.min_suffix_length, 
                                               min(content_length - cursor_position - middle_length, self.max_suffix_length))

                # Extract prefix, middle, and suffix based on token indices
                prefix_tokens = tokens[cursor_position - prefix_length:cursor_position]
                middle_tokens = tokens[cursor_position:cursor_position + middle_length]
                suffix_tokens = tokens[cursor_position + middle_length:cursor_position + middle_length + suffix_length]
                
                # Decode the tokenized segments back into text
                prefix = self.tokenizer.decode(prefix_tokens)
                middle = self.tokenizer.decode(middle_tokens)
                suffix = self.tokenizer.decode(suffix_tokens)

                # Create a sample in tuple format and add to the dataset
                self.examples.append((prefix, middle, suffix))
        
        # Restrict the dataset to num_samples by randomly selecting if necessary
        if len(self.examples) > num_samples:
            self.examples = random.sample(self.examples, num_samples)

    def __len__(self) -> int:
        """
        Returns the total number of examples in the dataset.
        Returns:
            int: The number of examples in the dataset.
        """
        return len(self.examples)
    
    def __getitem__(self, idx) -> tuple:
        """
        Retrieves the example at the specified index.
        Args:
            idx (int): The index of the example to retrieve.
        Returns:
            tuple: A tuple containing the prefix, middle, and suffix segments of the example.
        """
        return self.examples[idx]
